{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K70hAckqg0EA",
    "outputId": "33d478ab-f930-4bf6-fd7c-7b8cbbfee5d7"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.misc import toimage\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngfZDqIn169P"
   },
   "outputs": [],
   "source": [
    "## Plotting Functionsdef plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UF_GpLv18dK"
   },
   "outputs": [],
   "source": [
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 250\n",
    "l = 15\n",
    "nb_filter = 24\n",
    "compression = 0.46\n",
    "dropout_rate = 0.0\n",
    "growth_rate = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Schedule Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Md0-RFxigndF"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    #lrate = 0.001\n",
    "    lrate = 0.01\n",
    "    if epoch > 75:\n",
    "        #lrate = 0.0005\n",
    "        lrate = 0.001\n",
    "    elif epoch > 150:\n",
    "        #lrate = 0.0003\n",
    "        lrate = 0.001\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Step Decay function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqCYykoAaeSE"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "  initial_lrate = 0.1\n",
    "  drop = 0.5\n",
    "  epochs_drop = 10.0\n",
    "  lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "  lrate = 1e-6\n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "mB7o3zu1g6eT",
    "outputId": "5c5323e4-d1fc-486e-c534-056ea9bd17da"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoding \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Densenet Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression, growth_rate, nb_filter\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(growth_rate, (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        nb_filter += growth_rate\n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_filter * compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    GlobalAvg = GlobalAveragePooling2D()(relu)\n",
    "    #flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(GlobalAvg)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Densenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "#num_filter = 24\n",
    "#dropout_rate = 0.2\n",
    "#l = 12\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(nb_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, nb_filter, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, nb_filter, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, nb_filter, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, nb_filter, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, nb_filter, dropout_rate)\n",
    "#Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "output = output_layer(Third_Block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6398
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "6aebfec9-8299-40f8-d0e8-05f02db08eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 24)   648         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 32, 32, 24)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 32, 32, 24)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 12)   2592        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 32, 32, 36)   0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 32, 32, 36)   144         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 32, 32, 36)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 12)   3888        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 32, 32, 48)   0           concatenate_46[0][0]             \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 32, 32, 48)   192         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 32, 32, 48)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 12)   5184        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 32, 32, 60)   0           concatenate_47[0][0]             \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 32, 32, 60)   240         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 32, 32, 60)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 12)   6480        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 32, 32, 72)   0           concatenate_48[0][0]             \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 32, 32, 72)   288         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 32, 32, 72)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 12)   7776        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 32, 32, 84)   0           concatenate_49[0][0]             \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 32, 32, 84)   336         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 32, 32, 84)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 32, 12)   9072        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 32, 32, 96)   0           concatenate_50[0][0]             \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 32, 32, 96)   384         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 32, 32, 96)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 32, 12)   10368       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 32, 32, 108)  0           concatenate_51[0][0]             \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 32, 32, 108)  432         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 32, 32, 108)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 12)   11664       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 32, 32, 120)  0           concatenate_52[0][0]             \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 32, 32, 120)  480         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 32, 32, 120)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 12)   12960       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 32, 32, 132)  0           concatenate_53[0][0]             \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 32, 132)  528         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 32, 32, 132)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 12)   14256       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 32, 32, 144)  0           concatenate_54[0][0]             \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 32, 32, 144)  576         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 32, 32, 144)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 32, 12)   15552       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 32, 32, 156)  0           concatenate_55[0][0]             \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 32, 32, 156)  624         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 32, 32, 156)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 12)   16848       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 32, 32, 168)  0           concatenate_56[0][0]             \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 168)  672         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 168)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 12)   18144       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 32, 32, 180)  0           concatenate_57[0][0]             \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 180)  720         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 180)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 12)   19440       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 32, 32, 192)  0           concatenate_58[0][0]             \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 192)  768         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 32, 32, 12)   20736       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 32, 32, 204)  0           concatenate_59[0][0]             \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 32, 204)  816         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 204)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 93)   18972       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 16, 16, 93)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 93)   372         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 93)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 12)   10044       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 16, 16, 105)  0           average_pooling2d_3[0][0]        \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 105)  420         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 105)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 12)   11340       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 16, 16, 117)  0           concatenate_61[0][0]             \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 16, 117)  468         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 117)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 12)   12636       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 16, 16, 129)  0           concatenate_62[0][0]             \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 16, 129)  516         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 129)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 12)   13932       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 16, 16, 141)  0           concatenate_63[0][0]             \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 16, 141)  564         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 141)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 12)   15228       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 16, 16, 153)  0           concatenate_64[0][0]             \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 16, 153)  612         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 16, 153)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 12)   16524       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 16, 16, 165)  0           concatenate_65[0][0]             \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 165)  660         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 165)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 12)   17820       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 16, 16, 177)  0           concatenate_66[0][0]             \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 177)  708         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 177)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 12)   19116       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 16, 16, 189)  0           concatenate_67[0][0]             \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 189)  756         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 189)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 12)   20412       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 16, 16, 201)  0           concatenate_68[0][0]             \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 201)  804         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 201)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 12)   21708       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 16, 16, 213)  0           concatenate_69[0][0]             \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 213)  852         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 213)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 12)   23004       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 16, 16, 225)  0           concatenate_70[0][0]             \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 225)  900         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 225)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 12)   24300       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 16, 16, 237)  0           concatenate_71[0][0]             \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 237)  948         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 16, 237)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 12)   25596       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 16, 16, 249)  0           concatenate_72[0][0]             \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 16, 16, 249)  996         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 16, 16, 249)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 12)   26892       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 16, 16, 261)  0           concatenate_73[0][0]             \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 261)  1044        concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 261)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 12)   28188       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 16, 16, 273)  0           concatenate_74[0][0]             \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 273)  1092        concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 16, 16, 273)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 176)  48048       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 8, 8, 176)    0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 176)    704         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 176)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 12)     19008       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 8, 8, 188)    0           average_pooling2d_4[0][0]        \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 188)    752         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 188)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 12)     20304       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 8, 8, 200)    0           concatenate_76[0][0]             \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 200)    800         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 200)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 12)     21600       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 8, 8, 212)    0           concatenate_77[0][0]             \n",
      "                                                                 conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 212)    848         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 212)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 12)     22896       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 8, 8, 224)    0           concatenate_78[0][0]             \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 224)    896         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 224)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 12)     24192       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 8, 8, 236)    0           concatenate_79[0][0]             \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 236)    944         concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 236)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 12)     25488       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 8, 8, 248)    0           concatenate_80[0][0]             \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 248)    992         concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 248)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 12)     26784       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 8, 8, 260)    0           concatenate_81[0][0]             \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 260)    1040        concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 260)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 12)     28080       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 8, 8, 272)    0           concatenate_82[0][0]             \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 272)    1088        concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 272)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 12)     29376       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 8, 8, 284)    0           concatenate_83[0][0]             \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 284)    1136        concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 284)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 12)     30672       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 8, 8, 296)    0           concatenate_84[0][0]             \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 296)    1184        concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 296)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 12)     31968       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 8, 8, 308)    0           concatenate_85[0][0]             \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 308)    1232        concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 308)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 12)     33264       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 8, 8, 320)    0           concatenate_86[0][0]             \n",
      "                                                                 conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 320)    1280        concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 320)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 12)     34560       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 8, 8, 332)    0           concatenate_87[0][0]             \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 332)    1328        concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 332)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 12)     35856       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 8, 8, 344)    0           concatenate_88[0][0]             \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 344)    1376        concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 344)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 12)     37152       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 8, 8, 356)    0           concatenate_89[0][0]             \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 356)    1424        concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 356)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 356)          0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           3570        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 990,170\n",
      "Trainable params: 972,154\n",
      "Non-trainable params: 18,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "How_jcUCWhlC"
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NE92rHJDNsv8"
   },
   "outputs": [],
   "source": [
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Early Stopping Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0000, patience=6, \\\n",
    "                          verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LR Reducer Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.25,\n",
    "                              patience=4, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define checkpoint and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBCgLZtupeJm"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"./weights/weights_AWS.best.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#clr_triangular = CyclicLR(mode='triangular2')\n",
    "#clr_triangular = CyclicLR(base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular2')\n",
    "#callbacks_list = [checkpoint]\n",
    "#callbacks_list = [checkpoint, LearningRateScheduler(step_decay), earlystop]\n",
    "callbacks_list = [checkpoint, reduce_lr, earlystop]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1oTp_jR09VG"
   },
   "source": [
    "## Training - Epochs 1 to 51 (max val_acc: 91.02%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2683
    },
    "colab_type": "code",
    "id": "l4_dcujlA56p",
    "outputId": "dccecc9a-5904-4ded-fa6c-c8c5e8a9d1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "195/195 [==============================] - 318s 2s/step - loss: 1.4020 - acc: 0.4893 - val_loss: 3.6022 - val_acc: 0.3406\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.34060, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 2/250\n",
      "195/195 [==============================] - 262s 1s/step - loss: 0.9368 - acc: 0.6662 - val_loss: 1.2172 - val_acc: 0.5943\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.34060 to 0.59430, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 3/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.7428 - acc: 0.7412 - val_loss: 1.0892 - val_acc: 0.6393\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.59430 to 0.63930, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 4/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.6392 - acc: 0.7788 - val_loss: 1.2402 - val_acc: 0.6329\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.63930\n",
      "Epoch 5/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.5656 - acc: 0.8049 - val_loss: 1.0614 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.63930 to 0.68530, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 6/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.5118 - acc: 0.8215 - val_loss: 0.6858 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.68530 to 0.77540, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 7/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.4677 - acc: 0.8380 - val_loss: 1.0507 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77540\n",
      "Epoch 8/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.4348 - acc: 0.8488 - val_loss: 0.5242 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.77540 to 0.81720, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 9/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.4057 - acc: 0.8592 - val_loss: 1.1045 - val_acc: 0.7053\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.81720\n",
      "Epoch 10/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.3867 - acc: 0.8645 - val_loss: 0.6025 - val_acc: 0.8064\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81720\n",
      "Epoch 11/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.3622 - acc: 0.8730 - val_loss: 0.5943 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.81720 to 0.82050, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 12/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.3443 - acc: 0.8802 - val_loss: 0.5400 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.82050 to 0.82810, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 13/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.3314 - acc: 0.8846 - val_loss: 0.6832 - val_acc: 0.7906\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82810\n",
      "Epoch 14/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.3081 - acc: 0.8904 - val_loss: 1.0869 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82810\n",
      "Epoch 15/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.2947 - acc: 0.8976 - val_loss: 0.7799 - val_acc: 0.7915\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.82810\n",
      "Epoch 16/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.2821 - acc: 0.9001 - val_loss: 0.5424 - val_acc: 0.8415\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.82810 to 0.84150, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 17/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.2755 - acc: 0.9043 - val_loss: 0.5888 - val_acc: 0.8170\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84150\n",
      "Epoch 18/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.2606 - acc: 0.9087 - val_loss: 0.7014 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.84150\n",
      "Epoch 19/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.2556 - acc: 0.9119 - val_loss: 0.8124 - val_acc: 0.7609\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.84150\n",
      "Epoch 20/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.2399 - acc: 0.9155 - val_loss: 0.9853 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.84150\n",
      "Epoch 21/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.2367 - acc: 0.9175 - val_loss: 0.7828 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.84150\n",
      "Epoch 22/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1789 - acc: 0.9384 - val_loss: 0.3413 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.84150 to 0.88650, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 23/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1506 - acc: 0.9482 - val_loss: 0.3549 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.88650\n",
      "Epoch 24/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1483 - acc: 0.9477 - val_loss: 0.3095 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.88650 to 0.90100, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 25/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1430 - acc: 0.9499 - val_loss: 0.3395 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.90100\n",
      "Epoch 26/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1317 - acc: 0.9547 - val_loss: 0.3915 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.90100\n",
      "Epoch 27/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1336 - acc: 0.9533 - val_loss: 0.3605 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.90100\n",
      "Epoch 28/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1286 - acc: 0.9547 - val_loss: 0.3440 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.90100\n",
      "Epoch 29/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1257 - acc: 0.9558 - val_loss: 0.3030 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.90100 to 0.90660, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 30/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1270 - acc: 0.9553 - val_loss: 0.3677 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.90660\n",
      "Epoch 31/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1208 - acc: 0.9576 - val_loss: 0.3705 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.90660\n",
      "Epoch 32/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1215 - acc: 0.9565 - val_loss: 0.4047 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.90660\n",
      "Epoch 33/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1158 - acc: 0.9600 - val_loss: 0.3817 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.90660\n",
      "Epoch 34/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.1117 - acc: 0.9606 - val_loss: 0.3675 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.90660\n",
      "Epoch 35/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0983 - acc: 0.9656 - val_loss: 0.3077 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.90660 to 0.90980, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 36/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0903 - acc: 0.9683 - val_loss: 0.3148 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.90980\n",
      "Epoch 37/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0873 - acc: 0.9700 - val_loss: 0.3226 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.90980\n",
      "Epoch 38/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0875 - acc: 0.9704 - val_loss: 0.3222 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.90980\n",
      "Epoch 39/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0825 - acc: 0.9716 - val_loss: 0.3382 - val_acc: 0.9041\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.90980\n",
      "Epoch 40/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0856 - acc: 0.9704 - val_loss: 0.3306 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.90980\n",
      "Epoch 41/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0788 - acc: 0.9724 - val_loss: 0.3109 - val_acc: 0.9102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_acc improved from 0.90980 to 0.91020, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 42/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0769 - acc: 0.9735 - val_loss: 0.3201 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.91020\n",
      "Epoch 43/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0806 - acc: 0.9724 - val_loss: 0.3229 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.91020\n",
      "Epoch 44/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0768 - acc: 0.9737 - val_loss: 0.3184 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.91020\n",
      "Epoch 45/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0778 - acc: 0.9740 - val_loss: 0.3220 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.91020\n",
      "Epoch 46/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0750 - acc: 0.9741 - val_loss: 0.3190 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.91020\n",
      "Epoch 47/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0760 - acc: 0.9745 - val_loss: 0.3168 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.91020\n",
      "Epoch 48/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0745 - acc: 0.9748 - val_loss: 0.3166 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.91020\n",
      "Epoch 49/250\n",
      "195/195 [==============================] - 259s 1s/step - loss: 0.0746 - acc: 0.9746 - val_loss: 0.3169 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.91020\n",
      "Epoch 50/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0747 - acc: 0.9741 - val_loss: 0.3172 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.91020\n",
      "Epoch 51/250\n",
      "195/195 [==============================] - 260s 1s/step - loss: 0.0768 - acc: 0.9731 - val_loss: 0.3175 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.91020\n",
      "Epoch 00051: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,\\\n",
    "                    verbose=1, validation_data=(x_test,y_test),\\\n",
    "                    callbacks=callbacks_list) \n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1oTp_jR09VG"
   },
   "source": [
    "## Training - Epochs 51 to 78 (max val_acc: 92.44%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2683
    },
    "colab_type": "code",
    "id": "l4_dcujlA56p",
    "outputId": "dccecc9a-5904-4ded-fa6c-c8c5e8a9d1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 259s 5ms/step - loss: 0.0435 - acc: 0.9873 - val_loss: 0.2525 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.91020 to 0.92290, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0435 - acc: 0.9873 - val_loss: 0.2494 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92290 to 0.92380, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0429 - acc: 0.9873 - val_loss: 0.2489 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92380 to 0.92420, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0433 - acc: 0.9872 - val_loss: 0.2485 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92420\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0426 - acc: 0.9875 - val_loss: 0.2480 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92420\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0424 - acc: 0.9876 - val_loss: 0.2479 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92420\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0423 - acc: 0.9875 - val_loss: 0.2478 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92420\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0416 - acc: 0.9878 - val_loss: 0.2476 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92420\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0412 - acc: 0.9883 - val_loss: 0.2475 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92420\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0414 - acc: 0.9881 - val_loss: 0.2475 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92420\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0411 - acc: 0.9885 - val_loss: 0.2477 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92420\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0411 - acc: 0.9885 - val_loss: 0.2474 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92420 to 0.92430, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0414 - acc: 0.9879 - val_loss: 0.2475 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92430\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0416 - acc: 0.9877 - val_loss: 0.2475 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92430\n",
      "Epoch 15/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0412 - acc: 0.9881 - val_loss: 0.2474 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92430\n",
      "Epoch 16/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0409 - acc: 0.9880 - val_loss: 0.2475 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92430\n",
      "Epoch 17/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0411 - acc: 0.9884 - val_loss: 0.2473 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92430\n",
      "Epoch 18/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0408 - acc: 0.9883 - val_loss: 0.2474 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.92430 to 0.92440, saving model to ./weights/weights_AWS.best.h5\n",
      "Epoch 19/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0407 - acc: 0.9883 - val_loss: 0.2474 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92440\n",
      "Epoch 20/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0409 - acc: 0.9883 - val_loss: 0.2476 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92440\n",
      "Epoch 21/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0411 - acc: 0.9881 - val_loss: 0.2476 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92440\n",
      "Epoch 22/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0410 - acc: 0.9884 - val_loss: 0.2474 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92440\n",
      "Epoch 23/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0412 - acc: 0.9886 - val_loss: 0.2473 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.92440\n",
      "Epoch 24/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0414 - acc: 0.9879 - val_loss: 0.2474 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.92440\n",
      "Epoch 25/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0405 - acc: 0.9879 - val_loss: 0.2473 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.92440\n",
      "Epoch 26/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0410 - acc: 0.9883 - val_loss: 0.2473 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.92440\n",
      "Epoch 27/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0410 - acc: 0.9882 - val_loss: 0.2472 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.92440\n",
      "Epoch 28/250\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.0409 - acc: 0.9881 - val_loss: 0.2472 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.92440\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=callbacks_list)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "yzvKjFGh9sog",
    "outputId": "983d5e5c-e6ea-432b-a6a4-df2a885c7eff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model took 13308.52 seconds to train\n",
      "Accuracy on test data is: 90.85\n"
     ]
    }
   ],
   "source": [
    "# plot model history\n",
    "plot_model_history(model_info)\n",
    "print(\"Model took %0.2f seconds to train\" % (end - start))\n",
    "# compute test accuracy\n",
    "print(\"Accuracy on test data is: %0.2f\" % accuracy(x_test, y_test, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "ZcWydmIVhZGr",
    "outputId": "6447f948-9662-4ebb-ebeb-97cef59be371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 19s 2ms/step\n",
      "Test loss: 0.31753011630177497\n",
      "Test accuracy: 0.9085\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DNST_CIFAR10.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
